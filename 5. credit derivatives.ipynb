{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f586a4f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "\n",
    "import shap\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors\n",
    "from matplotlib.ticker import PercentFormatter\n",
    "from statsmodels.api import add_constant, OLS\n",
    "from xgboost import XGBRegressor\n",
    "from IPython.display import display\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf3cdbb0",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "### Auxiliary functions for data parsing and processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2505210e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_outliers(df):\n",
    "    \"\"\"\n",
    "    Removes outliers based on the median absolute deviation or\n",
    "    the mean absolute deviation when the former is zero.\n",
    "\n",
    "    :param df: input dataframe\n",
    "    :return: dataframe with outlier rows removed\n",
    "    \"\"\"\n",
    "    # Median Absolute Deviation\n",
    "    term = (df - df.median()).abs()\n",
    "    mad = 1.4826 * term.median()\n",
    "\n",
    "    mask = (mad != 0) if isinstance(mad, float) else mad.all()\n",
    "    if mask:\n",
    "        df = df[term / mad <= 3]\n",
    "    else:\n",
    "        # Mean Absolute Deviation\n",
    "        mad = 0.7979 * term.mean()\n",
    "        df = df[term / mad <= 3]\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def time_histograms(df, unit='hour'):\n",
    "    \"\"\"\n",
    "    Histogram plots of trading distribution per ticker\n",
    "    for a particular unit of time (e.g. day, hour, etc).\n",
    "\n",
    "    :param df: input dataframe\n",
    "    :param unit: time unit\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "    tickers = df['ticker'].unique()\n",
    "    fig, ax = plt.subplots(3, 1, figsize=(7, 10))\n",
    "    for i in range(3):\n",
    "        # determine the number of bins based on the time unit\n",
    "        nbins = 24 if unit == 'hour' else 60\n",
    "\n",
    "        # plot and configure histogram\n",
    "        N, bins, patches = ax[i].hist(df.loc[df['ticker'] == tickers[i], unit],\n",
    "                                      density=True, bins=np.arange(0, nbins) - 0.5)\n",
    "        ax[i].yaxis.set_major_formatter(PercentFormatter(xmax=1))\n",
    "        ax[i].set_xticks(range(0, nbins + 1, 2))\n",
    "        ax[i].set_yticks(np.arange(0, 0.175, 0.025))\n",
    "        ax[i].tick_params(axis='both', which='major', labelsize=14)\n",
    "        ax[i].text(0.8, 0.8, tickers[i], fontdict={'size': 15},\n",
    "                   transform=ax[i].transAxes)\n",
    "        ax[i].set_xlabel(unit.capitalize(), fontsize=17)\n",
    "        ax[i].set_ylabel('Percentage', fontsize=17)\n",
    "\n",
    "        # set colomap and bin colors\n",
    "        norm = colors.Normalize(N.min(), N.max())\n",
    "        for thisfrac, thispatch in zip(N, patches):\n",
    "            color = plt.cm.viridis(norm(thisfrac))\n",
    "            thispatch.set_facecolor(color)\n",
    "\n",
    "    ax[0].set_title('Histograms of daily trading activity', fontsize=18)\n",
    "    fig.tight_layout()\n",
    "    fig.show()\n",
    "\n",
    "\n",
    "def trade_direction(df):\n",
    "    \"\"\"\n",
    "    Feature engineering for spread first difference and direction of trade\n",
    "    using the \"tick-test\" method of Lee and Ready (1991) (see exercise 4).\n",
    "\n",
    "    :param df: input data\n",
    "    :return: data updated with direction of trade\n",
    "    \"\"\"\n",
    "    # spread first difference by ticker and replace the missing value for\n",
    "    # the first trade per ticker with a positive value to force a \"buy\" label\n",
    "    df['dspread'] = df.groupby('ticker')['spread'].diff()\n",
    "    df.loc[df['dspread'].isna(), 'dspread'] = 0.0001\n",
    "\n",
    "    # create the trade flow indicator based on spread first difference Δs:\n",
    "    # Δs > 0 -> buy, Δs < 0 -> sell, set Δs = 0 cases to missing for now\n",
    "    df['direction'] = np.select([df['dspread'] > 0, df['dspread'] < 0],\n",
    "                                ['buy', 'sell'], default=None)\n",
    "\n",
    "    # label zero-tick trades in the same direction as their preceding trades\n",
    "    df['direction'] = df['direction'].ffill()\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def trade_imbalance(df):\n",
    "    \"\"\"\n",
    "    Feature engineering for trade imbalance K = |cumsum(S) - cumsum(B)|,\n",
    "    where S = # of sell trades and B = # of buy trades during a day.\n",
    "\n",
    "    :param df: input data\n",
    "    :return: data updated with trade imbalance for each ticker\n",
    "    \"\"\"\n",
    "    # cumulative number of daily buy and sell orders per ticker\n",
    "    sells = df.assign(valid=df['direction'] == 'sell')\\\n",
    "        .groupby(['ticker', 'date']).valid.cumsum()\n",
    "    buys = df.assign(valid=df['direction'] == 'buy')\\\n",
    "        .groupby(['ticker', 'date']).valid.cumsum()\n",
    "\n",
    "    # define the trade imbalance feature\n",
    "    df['imbalance'] = np.abs(sells - buys)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6625694d",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "### Data parsing, processing and feature engineering\n",
    "\n",
    "**Trades with identical timestamp for each security**\n",
    "\n",
    "As already discussed in exercises 3 and 4, duplicate records for a security with identical timestampσ are possibly different trades rather than data errors. Trades with the same timestamp imply that the time interval between them was less than a second, but still non-zero because of latency. Trades in the data with a seemingly zero interval would add noise to any model that aims to predict arrival times. Therefore, I keep only the first trade that has the smallest latency and remove the others from sample, because noise increases with latency.\n",
    "\n",
    "**Notional value outliers and scale effects**\n",
    "\n",
    "The raw values for the notional include a heavy left tail. Although values below $10^5$ are likely fat finger trades (see below), their removal doesn't substantially mitigate the tail and scale effects as they consitute less than 1% of all trades in the sample. A log transform is more effective in mitigating left tail skewness and varying scale effects for this feature.\n",
    "\n",
    "**Fat finger trades**\n",
    "\n",
    "These are trades where either the notional or the spread (or both) entered the database with the wrong values, possibly because of human error or other sources of noise. Fat finger trades will be unidentifiable when the values recorded are in the vicinity of the sample distribution's mean and median. However, outlier trades are likely fat finger trades, especially if the trades that immediately precede and follow them have less extreme values. Therefore, I remove the outliers based on the Median Absolute Deviation (MAD) criteria (or the Mean Absolute Deviation if the former is zero). Outliers are identified for each ticker separately. Spread variables in this dataset seem to have fewer relatively extreme values per ticker compared to the notional. These values add explanatory power to the models that were tested. Therefore, they are not treated as outliers and are included in the sample.\n",
    "\n",
    "**Trading activity**\n",
    "\n",
    "Although OTC derivatives aren't subject to exchange hours, the histograms below show that ~90% of trading activity is concentrated primarily between 8 am - 4 pm for CDXIG5 and 3 am - 12 pm for the two European securities. Trades beyond these intervals will result in biased estimates for trade arrival intervals. Therefore, I restrict the sample to the hours of highest trading activity as specified above for each security. Although there is a small peak across all 3 securities at 10 am, each ticker's distribution can be considered roughly as uniform after the restriction is applied. As a result, there is no need to create separate models across the time of day. Also, there is a mild clustering of trades on the minute mark (0th second) for the European securities (roughtly 4% of total trades relatively to a uniform ~2% for every other second during a minute). Trading activity across minutes is also uniformly distributed.\n",
    "\n",
    "**Dependent variables**\n",
    "\n",
    "The dependent variables are *log(notional)* (explained before) and *log(dt)*, where *dt* is the vector of daily time intervals between successive trades in seconds. The logarithm on dt mitigates scale effects. The time intervals are constructed separately for each ticker and for each day. This is done to prevent spuriously large intervals between the last trade of a day and the first trade in the following day. The goal is to predict time intervals during periods of substantial trading activity.\n",
    "\n",
    "**Feature engineering**\n",
    "\n",
    "The list of features includes the following:  \n",
    "1. Time-related variables such as second, minute, hour and day.  \n",
    "2. The log-spread *log(spread)* and the nominal spread's first difference *Δspread*.  \n",
    "3. Daily trade imbalance (absolute difference between sells and buys).  \n",
    "4. Time-lagged (t-1) versions of the dependent variables.  \n",
    "5. Ticker dummies are also used in the regressions.\n",
    "\n",
    "The features *log(spread)*, *Δspread* and *imbalance* are lagged by one period, because the goal of the models is to forecast future values using the information available in the present."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f38c4082",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read dataset\n",
    "df = pd.read_csv(\"credit_derivatives_trades.csv\").drop(columns=['Unnamed: 0'])\n",
    "\n",
    "# keep only the first trade per ticker among those with identical timestamps\n",
    "df = df.drop_duplicates(subset=['ticker', 'timestamp'], keep='first')\n",
    "\n",
    "# convert timestamp to datetime and create auxiliary date variable\n",
    "df['timestamp'] = pd.to_datetime(df['timestamp'], format=\"%Y-%m-%d %H:%M:%S\")\n",
    "df['date'] = df['timestamp'].dt.date\n",
    "\n",
    "# sort by ticker and timestamp\n",
    "df = df.sort_values(by=['ticker', 'timestamp']).reset_index(drop=True)\n",
    "\n",
    "# sanity check and log transform the notional\n",
    "# to mitigate the feature's heavy left tail\n",
    "df = df[df['notional'] > 0]\n",
    "df['log(notional)'] = np.log(df['notional'])\n",
    "\n",
    "# get the daily time intervals in log-second units and log-spread\n",
    "df['logdt'] = np.log(df.groupby(['ticker', 'date'])\n",
    "                     ['timestamp'].diff().dt.total_seconds())\n",
    "df['log(spread)'] = np.log(df['spread'])\n",
    "\n",
    "# feature engineering of time variables\n",
    "df['day'] = df['timestamp'].dt.day\n",
    "df['hour'] = df['timestamp'].dt.hour\n",
    "df['minute'] = df['timestamp'].dt.minute\n",
    "df['second'] = df['timestamp'].dt.second\n",
    "\n",
    "# feature engineering of spread first difference and\n",
    "# trade imbalance (relies on direction of trade)\n",
    "df = trade_direction(df)\n",
    "df = trade_imbalance(df)\n",
    "\n",
    "# remove the outliers from log-notional and logdt.\n",
    "# extreme imbalance and spreads seem to improve forecasting.\n",
    "# cols = ['log(notional)', 'logdt', 'log(spread)', 'dspread', 'imbalance']\n",
    "cols = ['log(notional)', 'logdt']\n",
    "df[cols] = df.groupby('ticker')[cols].apply(remove_outliers)\n",
    "\n",
    "# show histogram plots and restrict the sample\n",
    "# within the hours of highest trading activity\n",
    "time_histograms(df, unit='hour')\n",
    "cols = ['ITXEB5', 'ITXES5']\n",
    "cond1 = (df['ticker'] == 'CDXIG5') & (df['hour'].between(8, 15))\n",
    "cond2 = (df['ticker'].isin(cols)) & (df['hour'].between(3, 11))\n",
    "df = df[(cond1) | (cond2)]\n",
    "\n",
    "# create ticker dummies\n",
    "df['D'] = df['ticker']\n",
    "df = pd.get_dummies(df, columns=['D'], drop_first=True, dtype=int)\n",
    "\n",
    "# lag the non-time related features\n",
    "cols = ['log(spread)', 'dspread', 'imbalance']\n",
    "df[cols] = df.groupby('ticker')[cols].shift()\n",
    "\n",
    "# create features by lagging the dependent variables\n",
    "lag_cols = ['laglog(notional)', 'laglogdt']\n",
    "df[lag_cols] = df.groupby('ticker')[['log(notional)', 'logdt']].shift()\n",
    "\n",
    "# clean up\n",
    "df = df.drop(columns=['direction', 'date', 'spread', 'notional'])\n",
    "\n",
    "# summary statistics for the new variable\n",
    "prc = [0.01, 0.25, 0.5, 0.75, 0.99]\n",
    "cols = ['log(notional)', 'logdt', 'log(spread)', 'dspread', 'imbalance']\n",
    "print('\\033[1m' + 'Summary Statistics' + '\\033[0m')\n",
    "display(df[cols].describe(percentiles=prc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20c7a349",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "### Auxiliary functions for model estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edb7b9e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_oos_r2(df, yvar):\n",
    "    \"\"\"\n",
    "    Estimates the performance metric (out-of-sample R-squared)\n",
    "    for a candidate model in the stepwise regression method.\n",
    "\n",
    "    :param df: dataframe with dependent variables and candidate features\n",
    "    :param yvar: dependent variable label\n",
    "    :return: model performance metric\n",
    "    \"\"\"\n",
    "    # configuration of dependent and independent variables\n",
    "    core = ['timestamp', yvar]\n",
    "    xcol = [col for col in df.columns if col not in core]\n",
    "\n",
    "    # sample test/train split\n",
    "    df_train = df[df['timestamp'].dt.year < 2017]\n",
    "    df_test = df[df['timestamp'].dt.year == 2017]\n",
    "\n",
    "    # train the model to estimate the OLS betas\n",
    "    exog = add_constant(df_train[xcol])\n",
    "    betas = OLS(df_train[yvar], exog, missing='drop').fit().params\n",
    "\n",
    "    # get OOS forecast by multiplying the betas from training\n",
    "    # with the feature values from the testing sample\n",
    "    exog = add_constant(df_test[xcol])\n",
    "    yhat = exog.mul(betas).sum(axis=1)\n",
    "\n",
    "    # estimate R-squared metric by fitting OOS predicted values\n",
    "    # with the observed ones for the same period\n",
    "    res = OLS(df_test[yvar], add_constant(yhat), missing='drop').fit()\n",
    "    oos_r2 = res.rsquared.round(4)\n",
    "\n",
    "    return oos_r2\n",
    "\n",
    "\n",
    "def stepwise(df, yvar):\n",
    "    \"\"\"\n",
    "    Performs a customized forward stepwise regression\n",
    "    for model estimation and feature importance.\n",
    "\n",
    "    :param df: dataframe with input features and regressors\n",
    "    :param yvar: dependent variable label\n",
    "    :return: dictionary with the summary of results\n",
    "    \"\"\"\n",
    "    # minimum OOS R-squared improvement threshold and feature containers\n",
    "    min_oos_r2 = 0.0001\n",
    "    selected_features = []\n",
    "    candidate_feature_pool = ['day', 'hour', 'minute', 'second', 'log(spread)',\n",
    "                              'dspread', 'imbalance', 'ticker',\n",
    "                              'laglog(notional)', 'laglogdt']\n",
    "\n",
    "    # append timestamp to yvar (for train/test split) and set dummy labels\n",
    "    core = ['timestamp', yvar]\n",
    "    dummies = ['D_ITXEB5', 'D_ITXES5']\n",
    "\n",
    "    # single run per candidate feature to restrict to those\n",
    "    # that contribute individually above the min threshold\n",
    "    oos_r2s_with_candidate_features = []\n",
    "    for candidate_feature in candidate_feature_pool:\n",
    "        if candidate_feature != 'ticker':\n",
    "            dft = df[core + [candidate_feature]]\n",
    "        else:\n",
    "            dft = df[core + dummies]\n",
    "        oos_r2 = get_oos_r2(dft, yvar)\n",
    "        oos_r2s_with_candidate_features.append((oos_r2, candidate_feature))\n",
    "    remaining_features = [tup[1] for tup in oos_r2s_with_candidate_features\n",
    "                          if tup[0] >= min_oos_r2]\n",
    "\n",
    "    # perform stepwise regression\n",
    "    current_oos_r2, best_new_oos_r2, delta_oos_r2 = 0.0, 0.0, -1.0\n",
    "    while (remaining_features and current_oos_r2 == best_new_oos_r2 and\n",
    "           delta_oos_r2 != 0.0):\n",
    "        oos_r2s_with_candidate_features = []\n",
    "        for candidate_feature in remaining_features:\n",
    "            if candidate_feature != 'ticker':\n",
    "                dft = df[core + selected_features + [candidate_feature]]\n",
    "            else:\n",
    "                dft = df[core + selected_features + dummies]\n",
    "            oos_r2 = get_oos_r2(dft, yvar)\n",
    "            oos_r2s_with_candidate_features.append((oos_r2, candidate_feature))\n",
    "\n",
    "        oos_r2s_with_candidate_features.sort()\n",
    "        best_new_oos_r2, best_candidate = oos_r2s_with_candidate_features.pop()\n",
    "        delta_oos_r2 = best_new_oos_r2 - current_oos_r2\n",
    "        if delta_oos_r2 > min_oos_r2:\n",
    "            current_oos_r2 = best_new_oos_r2\n",
    "            remaining_features.remove(best_candidate)\n",
    "            if best_candidate != 'ticker':\n",
    "                selected_features.append(best_candidate)\n",
    "            else:\n",
    "                selected_features.extend(dummies)\n",
    "\n",
    "    # get the best-performing basket of features with its OOS R-squared\n",
    "    if selected_features:\n",
    "        df_final = df[core + selected_features]\n",
    "        max_oos_r2 = get_oos_r2(df_final, yvar)\n",
    "    else:\n",
    "        selected_features = 'None'\n",
    "        max_oos_r2 = 0.0\n",
    "\n",
    "    # print results\n",
    "    print('\\033[1m' + 'Stepwise regression results for ' + yvar + '\\033[0m')\n",
    "    print('Model performance metric (OOS R-squared): {}'.format(max_oos_r2))\n",
    "    print('Feature importance (left-to-right): {}'.format(selected_features))\n",
    "\n",
    "\n",
    "def xgboost(df):\n",
    "    \"\"\"\n",
    "    Performs XGBoost regressions and feature importance with Shapley values for\n",
    "    each dependent variable separately to benchmark with the stepwise process.\n",
    "\n",
    "    :param df: dataframe with input features and regressors\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "    # sample test/train split (drop all NaN values)\n",
    "    df_train = df[df['timestamp'].dt.year < 2017].dropna()\n",
    "    df_test = df[df['timestamp'].dt.year == 2017].dropna()\n",
    "\n",
    "    # features list\n",
    "    xcol = ['day', 'hour', 'minute', 'second', 'log(spread)', 'dspread',\n",
    "            'imbalance', 'laglog(notional)', 'laglogdt', 'D_ITXEB5', 'D_ITXES5']\n",
    "\n",
    "    # load the boosted tree regressor class\n",
    "    xgr = XGBRegressor()\n",
    "\n",
    "    # loop over each dependent variable\n",
    "    for yvar in ['logdt', 'log(notional)']:\n",
    "        # fit the model in the training set\n",
    "        xgr.fit(df_train[xcol], df_train[yvar])\n",
    "\n",
    "        # get the model's OOS predictions in the testing set\n",
    "        yhat = xgr.predict(df_test[xcol])\n",
    "\n",
    "        # estimate OOS R-squared by OLS regression between observed\n",
    "        # and predicted values in the testing set, the intercept\n",
    "        # enforces the metric within [0, 1]\n",
    "        R2 = OLS(df_test[yvar], add_constant(yhat),\n",
    "                 missing='drop').fit().rsquared.round(4)\n",
    "\n",
    "        # print results\n",
    "        print('\\033[1m' + 'XGBoost regression results for ' + yvar + '\\033[0m')\n",
    "        print('Model performance metric (OOS R-squared): {}'.format(R2))\n",
    "        print('Feature importance plots with Shapley values')\n",
    "\n",
    "        # visualize feature importance results with Shapley values, they are\n",
    "        # more reliable that the internal importance methods of XGBoost\n",
    "        explainer = shap.TreeExplainer(xgr)\n",
    "        shap_values = explainer.shap_values(df_test[xcol])\n",
    "        shap.summary_plot(shap_values, df_test[xcol], plot_type=\"bar\")\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "def naive_benchmark(df):\n",
    "    \"\"\"\n",
    "    Performs an AR(1) regressions for each dependent variable to gauge\n",
    "    the performance improvement of the stepwise and boosting processe.\n",
    "\n",
    "    :param df: dataframe with input features and regressors\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "    # use the testing sample only\n",
    "    cols = ['logdt', 'log(notional)', 'laglogdt', 'laglog(notional)']\n",
    "    dfb = df.loc[df['timestamp'].dt.year == 2017, cols].copy()\n",
    "\n",
    "    # loop over each dependent variable\n",
    "    for yvar in ['logdt', 'log(notional)']:\n",
    "        # get the model's OOS predictions in the testing set\n",
    "        yhat = 'lag' + yvar\n",
    "\n",
    "        # estimate OOS R-squared by OLS regression between observed\n",
    "        # and predicted values in the testing set, the intercept\n",
    "        # enforces the metric within [0, 1]\n",
    "        R2 = OLS(dfb[yvar], add_constant(dfb[yhat]),\n",
    "                 missing='drop').fit().rsquared.round(4)\n",
    "\n",
    "        # print results\n",
    "        print('\\033[1m' + 'Naive benchmark results for ' + yvar + '\\033[0m')\n",
    "        print('Model performance metric (OOS R-squared): {}'.format(R2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "935436ea",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "## Model estimation\n",
    "\n",
    "The task, as it is phrased, is to develop a model that predicts both the arrival timestamp and the notional. A likely model to estimate both dependent variables simultaneously is VARX, i.e. a vector autoregression with $y_t = [dt_t, Q_t]$ across all securities ($Q_t$: notional) and additional exogenous features $X_t$. The intuition is that VARX enforces the coupling of lagged $y_{t-k}$ and $X_{t-k}$ values during the simultaneous estimation of vector $y_t$. This is something than can be justified by the presence of RV trades, where the exogenous features of one security can affect the $y_t$ values of the other security.\n",
    "\n",
    "However, the VARX solver from statsmodels uses MLE to estimate the model parameters and the solver is too slow for this data even for one regression. I use alternative methods that provide for the decoupling of the dependent variables. This implies that there will be a separate model estimation for the time interval $log(dt_t)$ and notional $log(Q_t)$, and the feature importance ranking will also differ for each dependent variable.\n",
    "\n",
    "The proposed estimation method is a custom forward stepwise regression. This method relies on a cascade of OLS regressions that provide for linearity, straightforward economic interpretability and feature importance with a parsimonious set of selected features. First, each feature is tested separately to gauge whether it has any explanatory power out-of-sample (OOS). Those that lack any power are removed from the list of candidate features. Those that have explanatory power are ranked in terms of OOS performance. The metric used for model selection is the OOS R-squared.\n",
    "\n",
    "The single feature with the best performance sets the core of features for the next round of OLS cascade estimations. During the second round, baskets of two features are tested successively by OLS. The basket for each of the regressions includes the core feature from the previous round and one of the remaining features in the candidate feature pool. These models are ranked by performance OOS again, and the pair of features that perform the best become the new core. The process is repeated recursively until the remaining features no longer provide any marginal performance improvement OOS, marking the end of the feature selection process.\n",
    "\n",
    "This process also provides for a feature importance method, as the first feature that is selected during the first round is the most important, the one selected in the second round is the second most important, etc. Features that are not selected don't provide any marginal performance improvement OOS, implying that they are not important for the estimation of the particular dependent variable.\n",
    "\n",
    "The stepwise regression method is benchmarked against two alternative methods. The first is a tree-based non-linear regression with XGBoost. The list of candidate features is relatively small, so boosting is preferred compared to random forests (RF). The reason is that RFs ensemble across multiple weak learners and work better with large lists of features. However, boosting methods recursively improve on the residuals of weak learners and can be effective even with smaller feature lists. The tree method is used to test weather potential non-linearity in the data can affect the end results of the stepwise regression and/or improve OOS performance substantially.\n",
    "\n",
    "XGBoost can also handle the ticker categorical feature, provided that it is encoded as dummies. Unlike OLS-based methods where one dummy must be excluded to prevent estimation failure from perfect collinearity, tree methods can handle that internally without any impact on model performance. However, the order of feature importance can be affected. Therefore, I exclude one of the dummies similarly to the stepwise method to mitigate the concerns of collinearity during the feature importance analysis.\n",
    "\n",
    "The second benchmark is a simple AR(1) process. The rationale is that the most naive forecast is a martingale, where the best prediction for next period's timestamp and notional are the currently observed values. The performance of the naive benchmark helps gauge the performance of the proposed models. For instance, an R-squared metric of 90% using sophisticated models would mean little if the naive benchmark had similar performance. For the test on the naive benchmark I use an OLS regression of OOS observed $y_t$ values on those predicted by the model $\\hat y_t = y_{t-1}$. Given that the predicted values are practically the lagged observed values, the estimation process is an $AR(1)$ rather than a strictly $I(1)$ martingale process, because the OLS beta won't likely be exactly equal to 1. However, this approach makes the test consistent with the estimation of OOS R-squared within the stepwise and boosting methods. Using OLS with an intercept to estimate the R-squared between $y_t$ and $\\hat y_t$ has the additional benefit that the metric is guarenteed to range $R^2\\in[0, 1]$ which facilitates the economic interpretability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "662f86cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stepwise regressions\n",
    "stepwise(df, 'logdt')\n",
    "stepwise(df, 'log(notional)')\n",
    "\n",
    "# XGBoost benchmark estimation\n",
    "xgboost(df)\n",
    "\n",
    "# naive benchmark, predicted values are the one-period\n",
    "# lags of observed values in the testing sample\n",
    "naive_benchmark(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64e29338",
   "metadata": {},
   "source": [
    "________\n",
    "\n",
    "## Conclusion\n",
    "\n",
    "Model performance for both the stepwise and XGBoost regressions outperforms the naive benchmark by roughly double the amount for each dependent variable. On the other hand, the OOS R-squared values are relatively low, because of the crude train/test data split and model setup. Trade data have intraday frequency and financial data overall tend to have a low signal-to-noise ratio. I usually test time series models OOS with one-period-ahead forecasting, because is it very hard to get robust multi-period forecasts with financial time series. However, for the purpose of demonstrating a complete ML time series analysis, the proposed data split suffices.\n",
    "\n",
    "The stepwise and XGBoost regressions have similar feature importance rankings. They both highlight first and foremost the importance of the security's contracting details (ticker/dummy variables). In order of importance, timestamp prediction is most sensitive to the most recently recorded interval, the trade imbalance and the spread respectively. The notional is harder to predict than the timestamp. Other than ticker ID, it is most sensitive to the spread. Compared to the stepwise regression, the XGBoost attributes more importance on the most recently recorded notional at the cost of dimished importance for the trade imbalance. However, the big picture on the feature importance results between the two methods is consistent."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
